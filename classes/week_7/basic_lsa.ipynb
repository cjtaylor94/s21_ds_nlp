{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_data = pd.read_csv('/Users/teacher/repos/f20_ds_nlp/classes/week_7/data/headlines', error_bad_lines=False);\n",
    "#raw_data = pd.read_csv(datafile, parse_dates=[0], infer_datetime_format=True)\n",
    "\n",
    "reindexed_data = raw_data['headline_text']\n",
    "reindexed_data.index = raw_data['publish_date']\n",
    "\n",
    "display(raw_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "small_count_vectorizer = CountVectorizer(stop_words='english', max_features=400)\n",
    "small_text_sample = reindexed_data.sample(n=10000, random_state=0)#.as_matrix()\n",
    "\n",
    "display(small_text_sample)\n",
    "small_document_term_matrix = small_count_vectorizer.fit_transform(small_text_sample)\n",
    "display(small_document_term_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_topics = 8\n",
    "\n",
    "lsa_model = TruncatedSVD(n_components=n_topics)\n",
    "lsa_topic_matrix = lsa_model.fit_transform(small_document_term_matrix)\n",
    "display(lsa_topic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Define helper functions\n",
    "def get_keys(topic_matrix):\n",
    "    '''returns an integer list of predicted topic categories for a given topic matrix'''\n",
    "    keys = []\n",
    "    for i in range(topic_matrix.shape[0]):\n",
    "        keys.append(topic_matrix[i].argmax())\n",
    "    return keys\n",
    "\n",
    "def keys_to_counts(keys):\n",
    "    '''returns a tuple of topic categories and their accompanying magnitudes for a given list of keys'''\n",
    "    count_pairs = Counter(keys).items()\n",
    "    categories = [pair[0] for pair in count_pairs]\n",
    "    counts = [pair[1] for pair in count_pairs]\n",
    "    return (categories, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_keys = get_keys(lsa_topic_matrix)\n",
    "lsa_categories, lsa_counts = keys_to_counts(lsa_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def get_top_n_words(n, keys, document_term_matrix, count_vectorizer):\n",
    "    '''returns a list of n_topic strings, where each string contains the n most common \n",
    "        words in a predicted category, in order'''\n",
    "    top_word_indices = []\n",
    "    for topic in range(n_topics):\n",
    "        temp_vector_sum = 0\n",
    "        for i in range(len(keys)):\n",
    "            if keys[i] == topic:\n",
    "                temp_vector_sum += document_term_matrix[i]\n",
    "        temp_vector_sum = temp_vector_sum.toarray()\n",
    "        top_n_word_indices = np.flip(np.argsort(temp_vector_sum)[0][-n:],0)\n",
    "        top_word_indices.append(top_n_word_indices)   \n",
    "    top_words = []\n",
    "    for topic in top_word_indices:\n",
    "        topic_words = []\n",
    "        for index in topic:\n",
    "            temp_word_vector = np.zeros((1,document_term_matrix.shape[1]))\n",
    "            temp_word_vector[:,index] = 1\n",
    "            the_word = count_vectorizer.inverse_transform(temp_word_vector)[0][0]\n",
    "            topic_words.append(the_word.encode('ascii').decode('utf-8'))\n",
    "        top_words.append(\" \".join(topic_words))         \n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "top_n_words_lsa = get_top_n_words(10, lsa_keys, small_document_term_matrix, small_count_vectorizer)\n",
    "\n",
    "for i in range(len(top_n_words_lsa)):\n",
    "    print(\"Topic {}: \".format(i), top_n_words_lsa[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "%matplotlib inline\n",
    "top_3_words = get_top_n_words(3, lsa_keys, small_document_term_matrix, small_count_vectorizer)\n",
    "labels = ['Topic {}: \\n'.format(i) + top_3_words[i] for i in lsa_categories]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.bar(lsa_categories, lsa_counts)\n",
    "ax.set_xticks(lsa_categories)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title('LSA Topic Category Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
